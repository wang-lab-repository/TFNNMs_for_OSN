{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"default\")\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_percentage_error,mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from utils import feature_impute, feature_impute_exiting, rf_fill\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import keras.backend as K\n",
    "from math import sqrt\n",
    "import time\n",
    "import datetime"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T02:14:13.177708Z",
     "iopub.execute_input": "2023-07-11T02:14:13.178462Z",
     "iopub.status.idle": "2023-07-11T02:14:15.405273Z",
     "shell.execute_reply.started": "2023-07-11T02:14:13.178423Z",
     "shell.execute_reply": "2023-07-11T02:14:15.404101Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_all=pd.read_excel(\"data.xlsx\")\n",
    "unseen=pd.read_excel(\"unseen_data_onehot.xlsx\")\n",
    "# df_all.columns\n",
    "Yc=['RP','RR']\n",
    "y=df_all[Yc]\n",
    "x=df_all.drop(Yc,axis=1)\n",
    "y_unseen = unseen[Yc]\n",
    "x_unseen = unseen.drop(Yc,axis=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T02:14:42.894212Z",
     "iopub.execute_input": "2023-07-11T02:14:42.894620Z",
     "iopub.status.idle": "2023-07-11T02:14:52.216650Z",
     "shell.execute_reply.started": "2023-07-11T02:14:42.894584Z",
     "shell.execute_reply": "2023-07-11T02:14:52.215354Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "need_delete=['Surface roughness']\n",
    "need_statistic_filling=['Permeability','Rejection/Selectivity','Amine concentration','Chloride concentration']\n",
    "need_model_filling=['Water contact angle','Solute concentration','NP size','Solute molecular weight']\n",
    "needed_model_filling=['Amine concentration','Chloride concentration','Chloride concentration','Rejection/Selectivity']\n",
    "x.drop(need_delete,axis=1,inplace=True)\n",
    "x_unseen.drop(need_delete,axis=1,inplace=True)\n",
    "filling=x[need_statistic_filling].mean()\n",
    "x[need_statistic_filling]=x[need_statistic_filling].fillna(dict(filling), inplace=False) ##\n",
    "x_unseen[need_statistic_filling]=x_unseen[need_statistic_filling].fillna(dict(filling), inplace=False) ##"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T02:15:06.041143Z",
     "iopub.execute_input": "2023-07-11T02:15:06.041918Z",
     "iopub.status.idle": "2023-07-11T02:15:06.065604Z",
     "shell.execute_reply.started": "2023-07-11T02:15:06.041883Z",
     "shell.execute_reply": "2023-07-11T02:15:06.064478Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model=[]\n",
    "for target, use_f in zip(need_model_filling,needed_model_filling):\n",
    "    x, m=feature_impute(x, target, use_f)\n",
    "    model.append(m)\n",
    "    rf_fill(x, target)\n",
    "for m, target, use_f in zip(model, need_model_filling, needed_model_filling):\n",
    "    x_unseen=feature_impute_exiting(x_unseen, target, use_f, model=m)\n",
    "    rf_fill(x_unseen, target)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T02:15:12.960767Z",
     "iopub.execute_input": "2023-07-11T02:15:12.961192Z",
     "iopub.status.idle": "2023-07-11T02:15:16.928413Z",
     "shell.execute_reply.started": "2023-07-11T02:15:12.961160Z",
     "shell.execute_reply": "2023-07-11T02:15:16.927183Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 对于将溶剂和溶质进行分子表征之后的数据， 应该将溶剂类型和溶质类型删除防止信息冗余\n",
    "df_all = pd.concat([x,x_unseen],axis=0) #########将x与x_unseen合并起来一起处理\n",
    "x = df_all.copy()\n",
    "# x.drop(['Solute_type'], axis=1, inplace=True) #, 'Solvent_type'\n",
    "is_delete = []\n",
    "x = pd.get_dummies(x)\n",
    "for c in x.columns:\n",
    "    if x[0:653][c].max() == 0:\n",
    "        is_delete.append(c)\n",
    "x.drop(columns=is_delete, axis=1, inplace=True)\n",
    "# 使用前者的最小值和最大值\n",
    "min = x.iloc[:653,:].min()\n",
    "max = x.iloc[:653,:].max()\n",
    "#对整个数据集进行变化\n",
    "x = (x - min) / max\n",
    "x_unseen=x.iloc[653:, :]\n",
    "x=x.iloc[:653, :]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, shuffle = True, random_state = 60)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T02:15:21.919307Z",
     "iopub.execute_input": "2023-07-11T02:15:21.919704Z",
     "iopub.status.idle": "2023-07-11T02:15:21.939911Z",
     "shell.execute_reply.started": "2023-07-11T02:15:21.919676Z",
     "shell.execute_reply": "2023-07-11T02:15:21.938766Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    scalar = 1.0*mean_squared_error(y_true[:,0],y_pred[:,0]) + 14.0*mean_squared_error(y_true[:,1], y_pred[:,1])\n",
    "    return scalar # 返回一个标量值 \n",
    "def build_model(n1=142, n2=16, lr=0.01, activation=\"relu\", p1 = 0.1, p2 = 0.1): \n",
    "    model = keras.Sequential( \n",
    "        [ \n",
    "            keras.layers.InputLayer(input_shape = 65),\n",
    "            keras.layers.Dense(units=n1, activation=activation, kernel_initializer=keras.initializers.he_normal(seed=42), bias_initializer='zeros'),\n",
    "            keras.layers.Dropout(rate=p1),\n",
    "            keras.layers.Dense(units=n2, activation=activation, kernel_initializer=keras.initializers.he_normal(seed=42), bias_initializer='zeros'),\n",
    "            keras.layers.Dropout(rate=p2),\n",
    "            keras.layers.Dense(units=2)\n",
    "        ] \n",
    "    ) \n",
    "    optimizer = keras.optimizers.Adam(lr = lr) \n",
    "    model.compile(optimizer = optimizer, loss = my_loss) #my_loss\n",
    "    return model \n",
    "\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                             min_delta=0,\n",
    "                                             patience=30,# 当评价指标没有提升时，等待的epochs数量，超过此数没有提升后训练将停止\n",
    "                                             verbose=0,\n",
    "                                             mode='min',\n",
    "                                             baseline=None,\n",
    "                                             restore_best_weights=True)\n",
    "callback2 = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                                                 patience=30, min_lr=0.00001)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T07:45:00.028818Z",
     "iopub.execute_input": "2023-07-11T07:45:00.029342Z",
     "iopub.status.idle": "2023-07-11T07:45:00.046992Z",
     "shell.execute_reply.started": "2023-07-11T07:45:00.029305Z",
     "shell.execute_reply": "2023-07-11T07:45:00.045631Z"
    },
    "trusted": true
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "scores1 = []\n",
    "scores2 = []\n",
    "t_scores1 = []\n",
    "t_scores2 = []\n",
    "\n",
    "rmse1 = []\n",
    "rmse2 = []\n",
    "t_rmse1 = []\n",
    "t_rmse2 = []\n",
    "\n",
    "mape1 = []\n",
    "mape2 = []\n",
    "t_mape1 = []\n",
    "t_mape2 = []\n",
    "\n",
    "mae1 = []\n",
    "mae2 = []\n",
    "t_mae1 = []\n",
    "t_mae2 = []"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T07:45:30.347908Z",
     "iopub.execute_input": "2023-07-11T07:45:30.348870Z",
     "iopub.status.idle": "2023-07-11T07:45:30.357164Z",
     "shell.execute_reply.started": "2023-07-11T07:45:30.348828Z",
     "shell.execute_reply": "2023-07-11T07:45:30.355944Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from math import sqrt\n",
    "kfold = KFold(n_splits = 5, shuffle=True, random_state=6)\n",
    "\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    model = build_model(n1 = 180, n2 = 70, lr=0.005, p1=0.10, p2=0.00)\n",
    "    model.fit(x_train.iloc[train], y_train.iloc[train], validation_data=(x_train.iloc[test],y_train.iloc[test]),epochs=3000, batch_size=32, verbose=0, callbacks=[callback1, callback2],shuffle=False, workers=1)\n",
    "    y_train_pred=model.predict(x_train.iloc[train])\n",
    "    y_val_pred=model.predict(x_train.iloc[test])\n",
    "    scores1.append(r2_score(y_train.iloc[test].values[:,0],y_val_pred[:,0]))\n",
    "    scores2.append(r2_score(y_train.iloc[test].values[:,1],y_val_pred[:,1]))\n",
    "    t_scores1.append(r2_score(y_train.iloc[train].values[:,0],y_train_pred[:,0]))\n",
    "    t_scores2.append(r2_score(y_train.iloc[train].values[:,1],y_train_pred[:,1]))\n",
    "    rmse1.append(sqrt(mean_squared_error(y_train.iloc[test].values[:,0],y_val_pred[:,0])))\n",
    "    rmse2.append(sqrt(mean_squared_error(y_train.iloc[test].values[:,1],y_val_pred[:,1])))\n",
    "    t_rmse1.append(sqrt(mean_squared_error(y_train.iloc[train].values[:,0],y_train_pred[:,0])))\n",
    "    t_rmse2.append(sqrt(mean_squared_error(y_train.iloc[train].values[:,1],y_train_pred[:,1])))\n",
    "    mape1.append(mean_absolute_percentage_error(y_train.iloc[test].values[:,0],y_val_pred[:,0]))\n",
    "    mape2.append(mean_absolute_percentage_error(y_train.iloc[test].values[:,1],y_val_pred[:,1]))\n",
    "    t_mape1.append(mean_absolute_percentage_error(y_train.iloc[train].values[:,0],y_train_pred[:,0]))\n",
    "    t_mape2.append(mean_absolute_percentage_error(y_train.iloc[train].values[:,1],y_train_pred[:,1]))\n",
    "    mae1.append(mean_absolute_error(y_train.iloc[test].values[:,0],y_val_pred[:,0]))\n",
    "    mae2.append(mean_absolute_error(y_train.iloc[test].values[:,1],y_val_pred[:,1]))\n",
    "    t_mae1.append(mean_absolute_error(y_train.iloc[train].values[:,0],y_train_pred[:,0]))\n",
    "    t_mae2.append(mean_absolute_error(y_train.iloc[train].values[:,1],y_train_pred[:,1]))\n",
    "print('r2:')\n",
    "print(f'train_mean1:{np.array(t_scores1).mean()}, train_std1:{np.array(t_scores1).std()}, \\\n",
    "        train_mean2:{np.array(t_scores2).mean()},train_std2:{np.array(t_scores2).std()},\\\n",
    "        test_mean1:{np.array(scores1).mean()}, test_std1:{np.array(scores1).std()},\\\n",
    "        test_mean2:{np.array(scores2).mean()}, test_std2:{np.array(scores2).std()}')\n",
    "print('\\n')\n",
    "print('rmse:')\n",
    "print(f'train_mean1:{np.array(t_rmse1).mean()}, train_std1:{np.array(t_rmse1).std()}, \\\n",
    "        train_mean2:{np.array(t_rmse2).mean()},train_std2:{np.array(t_rmse2).std()},\\\n",
    "        test_mean1:{np.array(rmse1).mean()}, test_std1:{np.array(rmse1).std()},\\\n",
    "        test_mean2:{np.array(rmse2).mean()}, test_std2:{np.array(rmse2).std()}')\n",
    "print('\\n')\n",
    "print('mape:')\n",
    "print(f'train_mean1:{np.array(t_mape1).mean()}, train_std1:{np.array(t_mape1).std()}, \\\n",
    "        train_mean2:{np.array(t_mape2).mean()},train_std2:{np.array(t_mape2).std()},\\\n",
    "        test_mean1:{np.array(mape1).mean()}, test_std1:{np.array(mape1).std()},\\\n",
    "        test_mean2:{np.array(mape2).mean()}, test_std2:{np.array(mape2).std()}')\n",
    "print('\\n')\n",
    "print('mae:')\n",
    "print(f'train_mean1:{np.array(t_mae1).mean()}, train_std1:{np.array(t_mae1).std()}, \\\n",
    "        train_mean2:{np.array(t_mae2).mean()},train_std2:{np.array(t_mae2).std()},\\\n",
    "        test_mean1:{np.array(mae1).mean()}, test_std1:{np.array(mae1).std()},\\\n",
    "        test_mean2:{np.array(mae2).mean()}, test_std2:{np.array(mae2).std()}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T07:50:37.555706Z",
     "iopub.execute_input": "2023-07-11T07:50:37.556214Z",
     "iopub.status.idle": "2023-07-11T07:51:41.302546Z",
     "shell.execute_reply.started": "2023-07-11T07:50:37.556178Z",
     "shell.execute_reply": "2023-07-11T07:51:41.301604Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# def save_crossvalidation(path):\n",
    "#     results=[]\n",
    "#     for i in [scores1,scores2,rmse1,rmse2,mape1,mape2,mae1,mae2,t_scores1,t_scores2,t_rmse1,t_rmse2,t_mape1,t_mape2,t_mae1,t_mae2]:\n",
    "#         results.append(np.array(i).mean())\n",
    "#         results.append(np.array(i).std())\n",
    "#     pd.DataFrame(results).to_excel(path+'.xlsx')\n",
    "# save_crossvalidation('onehot')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T07:49:07.213700Z",
     "iopub.execute_input": "2023-07-11T07:49:07.214180Z",
     "iopub.status.idle": "2023-07-11T07:49:07.258353Z",
     "shell.execute_reply.started": "2023-07-11T07:49:07.214141Z",
     "shell.execute_reply": "2023-07-11T07:49:07.256934Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "r2_test_rwp=[]\n",
    "r2_test_rsp=[]\n",
    "rmse_test_rwp=[]\n",
    "rmse_test_rsp=[]\n",
    "mape_test_rwp=[]\n",
    "mape_test_rsp=[]\n",
    "mae_test_rwp=[]\n",
    "mae_test_rsp=[]\n",
    "r2_train_rwp=[]\n",
    "r2_train_rsp=[]\n",
    "rmse_train_rwp=[]\n",
    "rmse_train_rsp=[]\n",
    "mape_train_rwp=[]\n",
    "mape_train_rsp=[]\n",
    "mae_train_rwp=[]\n",
    "mae_train_rsp=[]\n",
    "y_unseen_sum=np.zeros(y_unseen.shape)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T07:55:15.245899Z",
     "iopub.execute_input": "2023-07-11T07:55:15.246365Z",
     "iopub.status.idle": "2023-07-11T07:55:15.253829Z",
     "shell.execute_reply.started": "2023-07-11T07:55:15.246327Z",
     "shell.execute_reply": "2023-07-11T07:55:15.252496Z"
    },
    "trusted": true
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(seed=6):\n",
    "    tf.Session()\n",
    "    random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    K.set_session(sess)\n",
    "    model = build_model(n1 = 180, n2 = 70, lr=0.005, p1=0.10, p2=0.00)\n",
    "    model.fit(x_train, y_train, validation_split=0.2, epochs=3000, batch_size=32, verbose=0, callbacks=[callback1, callback2],shuffle=False,workers=1)\n",
    "    y_predt = model.predict(x_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_predu = model.predict(x_unseen)\n",
    "#     print(y_predu)\n",
    "    r2_test_rwp.append(r2_score(y_test.values[:, 0],y_pred[:, 0]))\n",
    "    r2_test_rsp.append(r2_score(y_test.values[:, 1],y_pred[:, 1]))\n",
    "    rmse_test_rwp.append(sqrt(mean_squared_error(y_test.values[:,0],y_pred[:,0])))\n",
    "    rmse_test_rsp.append(sqrt(mean_squared_error(y_test.values[:,1],y_pred[:,1])))\n",
    "    mape_test_rwp.append(mean_absolute_percentage_error(y_test.values[:,0],y_pred[:,0]))\n",
    "    mape_test_rsp.append(mean_absolute_percentage_error(y_test.values[:,1],y_pred[:,1]))\n",
    "    mae_test_rwp.append(mean_absolute_error(y_test.values[:,0],y_pred[:,0]))\n",
    "    mae_test_rsp.append(mean_absolute_error(y_test.values[:,1],y_pred[:,1]))\n",
    "    \n",
    "    r2_train_rwp.append(r2_score(y_train.values[:, 0],y_predt[:, 0]))\n",
    "    r2_train_rsp.append(r2_score(y_train.values[:, 1],y_predt[:, 1]))\n",
    "    rmse_train_rwp.append(sqrt(mean_squared_error(y_train.values[:, 0],y_predt[:, 0])))\n",
    "    rmse_train_rsp.append(sqrt(mean_squared_error(y_train.values[:, 1],y_predt[:, 1])))\n",
    "    mape_train_rwp.append(mean_absolute_percentage_error(y_train.values[:, 0],y_predt[:, 0]))\n",
    "    mape_train_rsp.append(mean_absolute_percentage_error(y_train.values[:, 1],y_predt[:, 1]))\n",
    "    mae_train_rwp.append(mean_absolute_error(y_train.values[:, 0],y_predt[:, 0]))\n",
    "    mae_train_rsp.append(mean_absolute_error(y_train.values[:, 1],y_predt[:, 1]))\n",
    "#     print('R2:',r2_score(y_test.values[:, 0],y_pred[:, 0]), r2_score(y_test.values[:, 1],y_pred[:, 1]))\n",
    "#     print(\"rmse:\",sqrt(mean_squared_error(y_test.values[:,0],y_pred[:,0])), sqrt(mean_squared_error(y_test.values[:,1],y_pred[:,1])))\n",
    "#     print(\"mape:\",mean_absolute_percentage_error(y_test.values[:,0],y_pred[:,0]), mean_absolute_percentage_error(y_test.values[:,1],y_pred[:,1]))\n",
    "#     print(\"mae:\",mean_absolute_error(y_test.values[:,0],y_pred[:,0]), mean_absolute_error(y_test.values[:,1],y_pred[:,1]))\n",
    "    return y_predu"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T07:55:15.616511Z",
     "iopub.execute_input": "2023-07-11T07:55:15.616957Z",
     "iopub.status.idle": "2023-07-11T07:55:15.636079Z",
     "shell.execute_reply.started": "2023-07-11T07:55:15.616921Z",
     "shell.execute_reply": "2023-07-11T07:55:15.634936Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import datetime\n",
    "starttime = datetime.datetime.now()\n",
    "for n, i in enumerate([random.choice([i for i in range(1000)]) for i in range(100)]):\n",
    "    y_unseen_temp = train(seed=i)\n",
    "    y_unseen_sum = y_unseen_sum+y_unseen_temp\n",
    "    endtime = datetime.datetime.now()\n",
    "    print(f'第{n+1}次随机种子测量，目前已耗时{(endtime - starttime).seconds} s')\n",
    "endtime = datetime.datetime.now()\n",
    "print(f'本次重复测量总共耗时：{(endtime - starttime).seconds}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T07:55:18.748028Z",
     "iopub.execute_input": "2023-07-11T07:55:18.748493Z",
     "iopub.status.idle": "2023-07-11T08:17:37.969435Z",
     "shell.execute_reply.started": "2023-07-11T07:55:18.748462Z",
     "shell.execute_reply": "2023-07-11T08:17:37.967617Z"
    },
    "trusted": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# results=[]\n",
    "# for i in [\n",
    "#     r2_train_rwp,r2_train_rsp,rmse_train_rwp,rmse_train_rsp,mape_train_rwp,mape_train_rsp,mae_train_rwp,mae_train_rsp,\n",
    "#     r2_test_rwp,r2_test_rsp,rmse_test_rwp,rmse_test_rsp,mape_test_rwp,mape_test_rsp,mae_test_rwp,mae_test_rsp\n",
    "# ]:\n",
    "#     results.append(np.array(i).mean())\n",
    "#     results.append(np.array(i).std())\n",
    "# pd.DataFrame(results).to_excel('onehot_metric.xlsx')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T08:18:22.597870Z",
     "iopub.execute_input": "2023-07-11T08:18:22.598520Z",
     "iopub.status.idle": "2023-07-11T08:18:22.626746Z",
     "shell.execute_reply.started": "2023-07-11T08:18:22.598469Z",
     "shell.execute_reply": "2023-07-11T08:18:22.625791Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# r2_train_rwp,r2_train_rsp,rmse_train_rwp,rmse_train_rsp,mape_train_rwp,mape_train_rsp,\\\n",
    "# mae_train_rwp,mae_train_rsp,r2_test_rwp,r2_test_rsp,rmse_test_rwp,rmse_test_rsp,mape_test_rwp,\\\n",
    "# mape_test_rsp,mae_test_rwp,mae_test_rsp = pd.DataFrame(r2_train_rwp),pd.DataFrame(r2_train_rsp),\\\n",
    "# pd.DataFrame(rmse_train_rwp),pd.DataFrame(rmse_train_rsp),pd.DataFrame(mape_train_rwp),\\\n",
    "# pd.DataFrame(mape_train_rsp),pd.DataFrame(mae_train_rwp),pd.DataFrame(mae_train_rsp),\\\n",
    "# pd.DataFrame(r2_test_rwp),pd.DataFrame(r2_test_rsp),pd.DataFrame(rmse_test_rwp),\\\n",
    "# pd.DataFrame(rmse_test_rsp),pd.DataFrame(mape_test_rwp),pd.DataFrame(mape_test_rsp),\\\n",
    "# pd.DataFrame(mae_test_rwp),pd.DataFrame(mae_test_rsp)\n",
    "# rfe_maccs_metrics=pd.concat([r2_train_rwp,r2_train_rsp,rmse_train_rwp,rmse_train_rsp,mape_train_rwp,mape_train_rsp,mae_train_rwp,mae_train_rsp,\n",
    "#             r2_test_rwp,r2_test_rsp,rmse_test_rwp,rmse_test_rsp,mape_test_rwp,mape_test_rsp,mae_test_rwp,mae_test_rsp],axis=1)\n",
    "# rfe_maccs_metrics.to_excel('onehot_100_metrics.xlsx')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-11T08:18:39.325027Z",
     "iopub.execute_input": "2023-07-11T08:18:39.325839Z",
     "iopub.status.idle": "2023-07-11T08:18:39.422864Z",
     "shell.execute_reply.started": "2023-07-11T08:18:39.325802Z",
     "shell.execute_reply": "2023-07-11T08:18:39.421563Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  }
 ]
}
