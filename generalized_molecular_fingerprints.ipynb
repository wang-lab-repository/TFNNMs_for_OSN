{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use(\"default\")\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_percentage_error,mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from utils import feature_impute, feature_impute_exiting, rf_fill, select_feature, plot_SSP\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import keras.backend as K\n",
    "from math import sqrt\n",
    "import time\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# import dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac24c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T13:37:02.514495Z",
     "iopub.status.busy": "2023-07-09T13:37:02.514023Z",
     "iopub.status.idle": "2023-07-09T13:37:12.280093Z",
     "shell.execute_reply": "2023-07-09T13:37:12.278669Z"
    },
    "papermill": {
     "duration": 9.777212,
     "end_time": "2023-07-09T13:37:12.283010",
     "exception": false,
     "start_time": "2023-07-09T13:37:02.505798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all=pd.read_excel(\"data.xlsx\")\n",
    "unseen=pd.read_excel(\"unseen_data_fingernet.xlsx\")\n",
    "# df_all.columns \n",
    "Yc=['RP', 'RR']\n",
    "y=df_all[Yc] \n",
    "x=df_all.drop(Yc, axis=1)\n",
    "y_unseen = unseen[Yc]\n",
    "x_unseen = unseen.drop(Yc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "need_delete=['Surface roughness']\n",
    "need_statistic_filling=['Permeability','Rejection/Selectivity','Amine concentration','Chloride concentration']\n",
    "need_model_filling=['Water contact angle','Solute concentration','NP size','Solute molecular weight']\n",
    "needed_model_filling=['Amine concentration','Chloride concentration','Chloride concentration','Rejection/Selectivity']\n",
    "x.drop(need_delete,axis=1,inplace=True)\n",
    "x_unseen.drop(need_delete,axis=1,inplace=True)\n",
    "filling=x[need_statistic_filling].mean()\n",
    "x[need_statistic_filling]=x[need_statistic_filling].fillna(dict(filling), inplace=False) ##\n",
    "x_unseen[need_statistic_filling]=x_unseen[need_statistic_filling].fillna(dict(filling), inplace=False) ##"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477737f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T13:37:12.358357Z",
     "iopub.status.busy": "2023-07-09T13:37:12.357900Z",
     "iopub.status.idle": "2023-07-09T13:37:16.311035Z",
     "shell.execute_reply": "2023-07-09T13:37:16.309656Z"
    },
    "papermill": {
     "duration": 3.963517,
     "end_time": "2023-07-09T13:37:16.313546",
     "exception": false,
     "start_time": "2023-07-09T13:37:12.350029",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model=[]\n",
    "for target, use_f in zip(need_model_filling,needed_model_filling):\n",
    "    x, m=feature_impute(x, target, use_f)\n",
    "    model.append(m)\n",
    "    rf_fill(x, target)\n",
    "for m, target, use_f in zip(model, need_model_filling, needed_model_filling):\n",
    "    x_unseen=feature_impute_exiting(x_unseen, target, use_f, model=m)\n",
    "    rf_fill(x_unseen, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a2defa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T13:37:16.329021Z",
     "iopub.status.busy": "2023-07-09T13:37:16.328603Z",
     "iopub.status.idle": "2023-07-09T13:37:17.652818Z",
     "shell.execute_reply": "2023-07-09T13:37:17.651662Z"
    },
    "papermill": {
     "duration": 1.33535,
     "end_time": "2023-07-09T13:37:17.655708",
     "exception": false,
     "start_time": "2023-07-09T13:37:16.320358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([x,x_unseen],axis=0)\n",
    "col = ['Logp', 'Tpsa', 'Qed', 'Hba', 'Hbd', 'Rob']\n",
    "col1 = ['Solvent_logp', 'Solvent_tpsa', 'Solvent_qed', 'Solvent_hba', 'Solvent_hbd', 'Solvent_rob']\n",
    "col2 = ['Solute_logp', 'Solute_tpsa', 'Solute_qed', 'Solute_hba', 'Solute_hbd', 'Solute_rob']\n",
    "smiles=pd.read_excel(\"smiles.xlsx\")\n",
    "solute = []\n",
    "for i in range(df_all.shape[0]):\n",
    "    if df_all.iloc[i]['Solute_type'] == 'AO':\n",
    "        solute.append(smiles.loc[10][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'BTB':\n",
    "        solute.append(smiles.loc[11][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'CV':\n",
    "        solute.append(smiles.loc[12][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'MB':\n",
    "        solute.append(smiles.loc[13][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'MO':\n",
    "        solute.append(smiles.loc[14][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'PEG':\n",
    "        solute.append(smiles.loc[15][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'RB':\n",
    "        solute.append(smiles.loc[16][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'RDB':\n",
    "        solute.append(smiles.loc[17][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'tetracycline':\n",
    "        solute.append(smiles.loc[18][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'oligomer':\n",
    "        solute.append(smiles.loc[19][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'SY':\n",
    "        solute.append(smiles.loc[20][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'EB':\n",
    "        solute.append(smiles.loc[21][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'RBBR':\n",
    "        solute.append(smiles.loc[22][col])\n",
    "    elif df_all.iloc[i]['Solute_type'] == 'SO':\n",
    "        solute.append(smiles.loc[23][col])\n",
    "df_all[col2] = solute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_all = pd.concat([x,x_unseen],axis=0) # Combine x and x_unseen to be processed together\n",
    "# col = []\n",
    "# col1 = []\n",
    "# col2 = []\n",
    "# for i in range(1024):\n",
    "#     col.append('Ecfp' + str(i))\n",
    "#     col1.append('Solvent_ecfp' + str(i))\n",
    "#     col2.append('Solute_ecfp' + str(i))\n",
    "# solute = []\n",
    "# for i in range(df_all.shape[0]):\n",
    "#     if df_all.iloc[i]['Solute_type'] == 'AO':\n",
    "#         solute.append(smiles.loc[10][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'BTB':\n",
    "#         solute.append(smiles.loc[11][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'CV':\n",
    "#         solute.append(smiles.loc[12][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'MB':\n",
    "#         solute.append(smiles.loc[13][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'MO':\n",
    "#         solute.append(smiles.loc[14][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'PEG':\n",
    "#         solute.append(smiles.loc[15][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'RB':\n",
    "#         solute.append(smiles.loc[16][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'RDB':\n",
    "#         solute.append(smiles.loc[17][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'tetracycline':\n",
    "#         solute.append(smiles.loc[18][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'oligomer':\n",
    "#         solute.append(smiles.loc[19][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'SY':\n",
    "#         solute.append(smiles.loc[20][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'EB':\n",
    "#         solute.append(smiles.loc[21][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'RBBR':\n",
    "#         solute.append(smiles.loc[22][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'SO':\n",
    "#         solute.append(smiles.loc[23][col])\n",
    "# df_all[col2] = solute"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_all = pd.concat([x,x_unseen],axis=0) # Combine x and x_unseen to be processed together\n",
    "# col=[]\n",
    "# col1=[]\n",
    "# col2=[]\n",
    "# for i in range(167):\n",
    "#     col.append('Maccs'+str(i))\n",
    "#     col1.append('Solvent_maccs'+str(i))\n",
    "#     col2.append('Solute_maccs'+str(i))\n",
    "#\n",
    "# solute=[]\n",
    "# for i in range(df_all.shape[0]):\n",
    "#     if df_all.iloc[i]['Solute_type'] == 'AO':\n",
    "#         solute.append(smiles.loc[10][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'BTB':\n",
    "#         solute.append(smiles.loc[11][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'CV':\n",
    "#         solute.append(smiles.loc[12][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'MB':\n",
    "#         solute.append(smiles.loc[13][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'MO':\n",
    "#         solute.append(smiles.loc[14][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'PEG':\n",
    "#         solute.append(smiles.loc[15][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'RB':\n",
    "#         solute.append(smiles.loc[16][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'RDB':\n",
    "#         solute.append(smiles.loc[17][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'tetracycline':\n",
    "#         solute.append(smiles.loc[18][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'oligomer':\n",
    "#         solute.append(smiles.loc[19][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'SY':\n",
    "#         solute.append(smiles.loc[20][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'EB':\n",
    "#         solute.append(smiles.loc[21][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'RBBR':\n",
    "#         solute.append(smiles.loc[22][col])\n",
    "#     elif df_all.iloc[i]['Solute_type'] == 'SO':\n",
    "#         solute.append(smiles.loc[23][col])\n",
    "# df_all[col2]=solute"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For data after molecular characterization of solvents and solutes,\n",
    "# solvent type and solute type should be removed to prevent redundancy of information.\n",
    "x=df_all.copy()\n",
    "x.drop(['Solute_type'], axis=1, inplace=True) #, 'Solvent_type'\n",
    "x=pd.get_dummies(x)\n",
    "is_delete = []\n",
    "for c in col2: # +col1\n",
    "    if x[0:653][c].max() == 0:\n",
    "        is_delete.append(c)\n",
    "x.drop(columns=is_delete, axis=1, inplace=True)\n",
    "# Use the minimum and maximum values of the former\n",
    "min = x.iloc[:653,:].min()\n",
    "max = x.iloc[:653,:].max()\n",
    "# Make changes to the entire dataset\n",
    "x = (x - min) / max\n",
    "x_unseen=x.iloc[653:, :]\n",
    "x=x.iloc[:653, :]\n",
    "# x, x_unseen = select_feature(x, y, x_unseen)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, shuffle = True, random_state = 60)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model building"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f379bae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T13:37:17.714388Z",
     "iopub.status.busy": "2023-07-09T13:37:17.713971Z",
     "iopub.status.idle": "2023-07-09T13:37:18.144360Z",
     "shell.execute_reply": "2023-07-09T13:37:18.143396Z"
    },
    "papermill": {
     "duration": 0.441802,
     "end_time": "2023-07-09T13:37:18.147026",
     "exception": false,
     "start_time": "2023-07-09T13:37:17.705224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    scalar = 1.0*mean_squared_error(y_true[:,0],y_pred[:,0]) + 14.0*mean_squared_error(y_true[:,1], y_pred[:,1])\n",
    "    return scalar\n",
    "def build_model(n1=142, n2=16, lr=0.01, activation=\"relu\", p1 = 0.1, p2 = 0.1): \n",
    "    model = keras.Sequential( \n",
    "        [ \n",
    "            keras.layers.InputLayer(input_shape = 61),\n",
    "            keras.layers.Dense(units=n1, activation=activation, kernel_initializer=keras.initializers.he_normal(seed=42), bias_initializer='zeros'),\n",
    "            keras.layers.Dropout(rate=p1),\n",
    "            keras.layers.Dense(units=n2, activation=activation, kernel_initializer=keras.initializers.he_normal(seed=42), bias_initializer='zeros'),\n",
    "            keras.layers.Dropout(rate=p2),\n",
    "            keras.layers.Dense(units=2)\n",
    "        ] \n",
    "    ) \n",
    "    optimizer = keras.optimizers.Adam(lr = lr) \n",
    "    model.compile(optimizer = optimizer, loss = my_loss) #my_loss\n",
    "    return model \n",
    "\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                             min_delta=0,\n",
    "                                             patience=30,\n",
    "# The number of epochs to wait for when the evaluation metrics are not boosted, beyond which training will stop after no boosts are made\n",
    "                                             verbose=0,\n",
    "                                             mode='min',\n",
    "                                             baseline=None,\n",
    "                                             restore_best_weights=True)\n",
    "callback2 = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n",
    "                                                 patience=30, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e0d1432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T13:37:18.163573Z",
     "iopub.status.busy": "2023-07-09T13:37:18.162480Z",
     "iopub.status.idle": "2023-07-10T00:37:41.121579Z",
     "shell.execute_reply": "2023-07-10T00:37:41.120586Z"
    },
    "papermill": {
     "duration": 39623.797273,
     "end_time": "2023-07-10T00:37:41.951155",
     "exception": false,
     "start_time": "2023-07-09T13:37:18.153882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores1 = []\n",
    "scores2 = []\n",
    "t_scores1 = []\n",
    "t_scores2 = []\n",
    "\n",
    "rmse1 = []\n",
    "rmse2 = []\n",
    "t_rmse1 = []\n",
    "t_rmse2 = []\n",
    "\n",
    "mape1 = []\n",
    "mape2 = []\n",
    "t_mape1 = []\n",
    "t_mape2 = []\n",
    "\n",
    "mae1 = []\n",
    "mae2 = []\n",
    "t_mae1 = []\n",
    "t_mae2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14001c",
   "metadata": {
    "papermill": {
     "duration": 0.943672,
     "end_time": "2023-07-10T00:37:44.005232",
     "exception": false,
     "start_time": "2023-07-10T00:37:43.061560",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle=True, random_state=6)\n",
    "\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    model = build_model(n1 = 338, n2 = 73, lr=0.003, p1=0.1, p2=0)\n",
    "    model.fit(x_train.iloc[train], y_train.iloc[train], validation_data=(x_train.iloc[test],y_train.iloc[test]),epochs=3000, batch_size=32, verbose=0, callbacks=[callback1, callback2],shuffle=False, workers=1)\n",
    "    y_train_pred=model.predict(x_train.iloc[train])\n",
    "    y_val_pred=model.predict(x_train.iloc[test])\n",
    "    scores1.append(r2_score(y_train.iloc[test].values[:,0],y_val_pred[:,0]))\n",
    "    scores2.append(r2_score(y_train.iloc[test].values[:,1],y_val_pred[:,1]))\n",
    "    t_scores1.append(r2_score(y_train.iloc[train].values[:,0],y_train_pred[:,0]))\n",
    "    t_scores2.append(r2_score(y_train.iloc[train].values[:,1],y_train_pred[:,1]))\n",
    "    rmse1.append(sqrt(mean_squared_error(y_train.iloc[test].values[:,0],y_val_pred[:,0])))\n",
    "    rmse2.append(sqrt(mean_squared_error(y_train.iloc[test].values[:,1],y_val_pred[:,1])))\n",
    "    t_rmse1.append(sqrt(mean_squared_error(y_train.iloc[train].values[:,0],y_train_pred[:,0])))\n",
    "    t_rmse2.append(sqrt(mean_squared_error(y_train.iloc[train].values[:,1],y_train_pred[:,1])))\n",
    "    mape1.append(mean_absolute_percentage_error(y_train.iloc[test].values[:,0],y_val_pred[:,0]))\n",
    "    mape2.append(mean_absolute_percentage_error(y_train.iloc[test].values[:,1],y_val_pred[:,1]))\n",
    "    t_mape1.append(mean_absolute_percentage_error(y_train.iloc[train].values[:,0],y_train_pred[:,0]))\n",
    "    t_mape2.append(mean_absolute_percentage_error(y_train.iloc[train].values[:,1],y_train_pred[:,1]))\n",
    "    mae1.append(mean_absolute_error(y_train.iloc[test].values[:,0],y_val_pred[:,0]))\n",
    "    mae2.append(mean_absolute_error(y_train.iloc[test].values[:,1],y_val_pred[:,1]))\n",
    "    t_mae1.append(mean_absolute_error(y_train.iloc[train].values[:,0],y_train_pred[:,0]))\n",
    "    t_mae2.append(mean_absolute_error(y_train.iloc[train].values[:,1],y_train_pred[:,1]))\n",
    "print('r2:')\n",
    "print(f'train_mean1:{np.array(t_scores1).mean()}, train_std1:{np.array(t_scores1).std()}, \\\n",
    "        train_mean2:{np.array(t_scores2).mean()},train_std2:{np.array(t_scores2).std()},\\\n",
    "        test_mean1:{np.array(scores1).mean()}, test_std1:{np.array(scores1).std()},\\\n",
    "        test_mean2:{np.array(scores2).mean()}, test_std2:{np.array(scores2).std()}')\n",
    "print('\\n')\n",
    "print('rmse:')\n",
    "print(f'train_mean1:{np.array(t_rmse1).mean()}, train_std1:{np.array(t_rmse1).std()}, \\\n",
    "        train_mean2:{np.array(t_rmse2).mean()},train_std2:{np.array(t_rmse2).std()},\\\n",
    "        test_mean1:{np.array(rmse1).mean()}, test_std1:{np.array(rmse1).std()},\\\n",
    "        test_mean2:{np.array(rmse2).mean()}, test_std2:{np.array(rmse2).std()}')\n",
    "print('\\n')\n",
    "print('mape:')\n",
    "print(f'train_mean1:{np.array(t_mape1).mean()}, train_std1:{np.array(t_mape1).std()}, \\\n",
    "        train_mean2:{np.array(t_mape2).mean()},train_std2:{np.array(t_mape2).std()},\\\n",
    "        test_mean1:{np.array(mape1).mean()}, test_std1:{np.array(mape1).std()},\\\n",
    "        test_mean2:{np.array(mape2).mean()}, test_std2:{np.array(mape2).std()}')\n",
    "print('\\n')\n",
    "print('mae:')\n",
    "print(f'train_mean1:{np.array(t_mae1).mean()}, train_std1:{np.array(t_mae1).std()}, \\\n",
    "        train_mean2:{np.array(t_mae2).mean()}, train_std2:{np.array(t_mae2).std()},\\\n",
    "        test_mean1:{np.array(mae1).mean()}, test_std1:{np.array(mae1).std()},\\\n",
    "        test_mean2:{np.array(mae2).mean()}, test_std2:{np.array(mae2).std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "r2_test_rwp=[]\n",
    "r2_test_rsp=[]\n",
    "rmse_test_rwp=[]\n",
    "rmse_test_rsp=[]\n",
    "mape_test_rwp=[]\n",
    "mape_test_rsp=[]\n",
    "mae_test_rwp=[]\n",
    "mae_test_rsp=[]\n",
    "r2_train_rwp=[]\n",
    "r2_train_rsp=[]\n",
    "rmse_train_rwp=[]\n",
    "rmse_train_rsp=[]\n",
    "mape_train_rwp=[]\n",
    "mape_train_rsp=[]\n",
    "mae_train_rwp=[]\n",
    "mae_train_rsp=[]\n",
    "y_unseen_sum=np.zeros(y_unseen.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def train(seed=6):\n",
    "    tf.Session()\n",
    "    random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    K.set_session(sess)\n",
    "    model = build_model(n1 = 338, n2 = 73, lr=0.003, p1=0.1, p2=0)\n",
    "    model.fit(x_train, y_train, validation_split=0.2, epochs=3000, batch_size=32, verbose=0, callbacks=[callback1, callback2],shuffle=False,workers=1)\n",
    "    y_predt = model.predict(x_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_predu = model.predict(x_unseen)\n",
    "#     print(y_predu)\n",
    "    r2_test_rwp.append(r2_score(y_test.values[:, 0],y_pred[:, 0]))\n",
    "    r2_test_rsp.append(r2_score(y_test.values[:, 1],y_pred[:, 1]))\n",
    "    rmse_test_rwp.append(sqrt(mean_squared_error(y_test.values[:,0],y_pred[:,0])))\n",
    "    rmse_test_rsp.append(sqrt(mean_squared_error(y_test.values[:,1],y_pred[:,1])))\n",
    "    mape_test_rwp.append(mean_absolute_percentage_error(y_test.values[:,0],y_pred[:,0]))\n",
    "    mape_test_rsp.append(mean_absolute_percentage_error(y_test.values[:,1],y_pred[:,1]))\n",
    "    mae_test_rwp.append(mean_absolute_error(y_test.values[:,0],y_pred[:,0]))\n",
    "    mae_test_rsp.append(mean_absolute_error(y_test.values[:,1],y_pred[:,1]))\n",
    "\n",
    "    r2_train_rwp.append(r2_score(y_train.values[:, 0],y_predt[:, 0]))\n",
    "    r2_train_rsp.append(r2_score(y_train.values[:, 1],y_predt[:, 1]))\n",
    "    rmse_train_rwp.append(sqrt(mean_squared_error(y_train.values[:, 0],y_predt[:, 0])))\n",
    "    rmse_train_rsp.append(sqrt(mean_squared_error(y_train.values[:, 1],y_predt[:, 1])))\n",
    "    mape_train_rwp.append(mean_absolute_percentage_error(y_train.values[:, 0],y_predt[:, 0]))\n",
    "    mape_train_rsp.append(mean_absolute_percentage_error(y_train.values[:, 1],y_predt[:, 1]))\n",
    "    mae_train_rwp.append(mean_absolute_error(y_train.values[:, 0],y_predt[:, 0]))\n",
    "    mae_train_rsp.append(mean_absolute_error(y_train.values[:, 1],y_predt[:, 1]))\n",
    "#     print('R2:',r2_score(y_test.values[:, 0],y_pred[:, 0]), r2_score(y_test.values[:, 1],y_pred[:, 1]))\n",
    "#     print(\"rmse:\",sqrt(mean_squared_error(y_test.values[:,0],y_pred[:,0])), sqrt(mean_squared_error(y_test.values[:,1],y_pred[:,1])))\n",
    "#     print(\"mape:\",mean_absolute_percentage_error(y_test.values[:,0],y_pred[:,0]), mean_absolute_percentage_error(y_test.values[:,1],y_pred[:,1]))\n",
    "#     print(\"mae:\",mean_absolute_error(y_test.values[:,0],y_pred[:,0]), mean_absolute_error(y_test.values[:,1],y_pred[:,1]))\n",
    "    return y_predu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "for n, i in enumerate([random.choice([i for i in range(1000)]) for i in range(100)]):\n",
    "    y_unseen_temp = train(seed=i)\n",
    "    y_unseen_sum = y_unseen_sum+y_unseen_temp\n",
    "    endtime = datetime.datetime.now()\n",
    "    print(f'The {n+1} th randomized seed measurement, which has now taken time{(endtime - starttime).seconds} s')\n",
    "endtime = datetime.datetime.now()\n",
    "print(f'The total time taken for this repeat measurementï¼š{(endtime - starttime).seconds}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# shap summary plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('***.keras', compile = False)\n",
    "# plot_SSP(model, col='NP size', x_train=x_train, x_test=x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39677.786794,
   "end_time": "2023-07-10T00:37:48.685140",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-09T13:36:30.898346",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
